{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar fechas fuera del rango necesario en MYSQL\n",
    "\n",
    "Se utiliza un codigo ejecutado local o en colab para limpieza de Taxis_fhv_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting deletion process...\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
    "    filename='database_deletion.log'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DatabaseManager:\n",
    "    def __init__(self):\n",
    "        # Load environment variables\n",
    "        load_dotenv()\n",
    "\n",
    "        # Get database credentials from environment variables\n",
    "        self.db_host = os.getenv('DB_HOST')\n",
    "        self.db_user = os.getenv('DB_USER')\n",
    "        self.db_password = os.getenv('DB_PASSWORD')\n",
    "        self.db_name = os.getenv('DB_NAME')\n",
    "\n",
    "    def _create_connection(self):\n",
    "        \"\"\"Create a database connection\"\"\"\n",
    "        try:\n",
    "            conn = mysql.connector.connect(\n",
    "                host=self.db_host,\n",
    "                user=self.db_user,\n",
    "                password=self.db_password,\n",
    "                database=self.db_name\n",
    "            )\n",
    "            return conn\n",
    "        except mysql.connector.Error as err:\n",
    "            logger.error(f\"Connection error: {err}\")\n",
    "            raise\n",
    "\n",
    "    def delete_records_outside_date_range(self, start_date, end_date, batch_size=10000):\n",
    "        \"\"\"\n",
    "        Delete records outside specified date range with retry and batching\n",
    "        \n",
    "        :param start_date: Start date for keeping records\n",
    "        :param end_date: End date for keeping records\n",
    "        :param batch_size: Number of records to delete in each batch\n",
    "        \"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        total_deleted = 0\n",
    "\n",
    "        try:\n",
    "            conn = self._create_connection()\n",
    "            conn.autocommit = False  # Disable autocommit\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Print and log start of deletion process\n",
    "            print(\"Starting deletion process...\")\n",
    "            logger.info(\"Starting deletion process...\")\n",
    "\n",
    "            # Validate date format\n",
    "            try:\n",
    "                datetime.strptime(start_date, '%Y-%m-%d')\n",
    "                datetime.strptime(end_date, '%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                logger.error(\"Invalid date format. Use YYYY-MM-DD\")\n",
    "                print(\"Invalid date format. Use YYYY-MM-DD\")\n",
    "                return 0\n",
    "\n",
    "            # Initial check to estimate total records to delete\n",
    "            count_query = f\"\"\"\n",
    "            SELECT COUNT(*) FROM taxi_fhv_data \n",
    "            WHERE NOT (Pickup_datetime BETWEEN '{start_date}' AND '{end_date}')\n",
    "            \"\"\"\n",
    "            cursor.execute(count_query)\n",
    "            total_records = cursor.fetchone()[0]\n",
    "            logger.info(f\"Total records to delete: {total_records}\")\n",
    "            print(f\"Total records to delete: {total_records}\")\n",
    "\n",
    "            # Delete in batches to reduce lock contention\n",
    "            while True:\n",
    "                delete_query = f\"\"\"\n",
    "                DELETE FROM taxi_fhv_data \n",
    "                WHERE NOT (Pickup_datetime BETWEEN '{start_date}' AND '{end_date}')\n",
    "                LIMIT {batch_size}\n",
    "                \"\"\"\n",
    "\n",
    "                # Retry mechanism with exponential backoff\n",
    "                max_retries = 5\n",
    "                for attempt in range(max_retries):\n",
    "                    try:\n",
    "                        cursor.execute(delete_query)\n",
    "                        conn.commit()\n",
    "                        rows_deleted = cursor.rowcount\n",
    "                        total_deleted += rows_deleted\n",
    "\n",
    "                        logger.info(f\"Batch delete - Rows deleted: {rows_deleted}\")\n",
    "                        print(f\"Batch delete - Rows deleted: {rows_deleted}\")\n",
    "\n",
    "                        # Exit if no more records to delete\n",
    "                        if rows_deleted == 0:\n",
    "                            break\n",
    "\n",
    "                        break  # Successful deletion\n",
    "                    except mysql.connector.Error as err:\n",
    "                        if err.errno == 1205:  # Lock wait timeout\n",
    "                            wait_time = 2 ** attempt\n",
    "                            logger.warning(f\"Lock timeout. Retry {attempt + 1}/{max_retries}. Waiting {wait_time} seconds\")\n",
    "                            print(f\"Lock timeout. Retry {attempt + 1}/{max_retries}. Waiting {wait_time} seconds\")\n",
    "                            time.sleep(wait_time)\n",
    "                            conn.rollback()\n",
    "                        else:\n",
    "                            raise\n",
    "\n",
    "                # Break main loop if no more records\n",
    "                if rows_deleted == 0:\n",
    "                    break\n",
    "\n",
    "            logger.info(f\"Total records deleted: {total_deleted}\")\n",
    "            print(f\"Total records deleted: {total_deleted}\")\n",
    "            return total_deleted\n",
    "\n",
    "        except Exception as e:\n",
    "            if conn:\n",
    "                conn.rollback()\n",
    "            logger.error(f\"Deletion error: {e}\")\n",
    "            print(f\"Deletion error: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            # Ensure resources are closed\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "            \n",
    "            # Print and log end of deletion process\n",
    "            print(\"Deletion process completed.\")\n",
    "            logger.info(\"Deletion process completed.\")\n",
    "\n",
    "def main():\n",
    "    # Execution\n",
    "    db_manager = DatabaseManager()\n",
    "    start_date = '2024-01-01'\n",
    "    end_date = '2024-08-31'\n",
    "    \n",
    "    try:\n",
    "        deleted_count = db_manager.delete_records_outside_date_range(start_date, end_date)\n",
    "        print(f\"Successfully deleted {deleted_count} records.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Deletion process failed: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar FHV en taxi_fhv_data\n",
    "\n",
    "se elimina por fecha cada 15 dias por temas de optimizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting deletion process...\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
    "    filename='database_deletion.log'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DatabaseManager:\n",
    "    def __init__(self):\n",
    "        # Load environment variables\n",
    "        load_dotenv()\n",
    "\n",
    "        # Get database credentials from environment variables\n",
    "        self.db_host = os.getenv('DB_HOST')\n",
    "        self.db_user = os.getenv('DB_USER')\n",
    "        self.db_password = os.getenv('DB_PASSWORD')\n",
    "        self.db_name = os.getenv('DB_NAME')\n",
    "\n",
    "    def _create_connection(self):\n",
    "        \"\"\"Create a database connection\"\"\"\n",
    "        try:\n",
    "            conn = mysql.connector.connect(\n",
    "                host=self.db_host,\n",
    "                user=self.db_user,\n",
    "                password=self.db_password,\n",
    "                database=self.db_name\n",
    "            )\n",
    "            return conn\n",
    "        except mysql.connector.Error as err:\n",
    "            logger.error(f\"ðŸ”´ Connection error: {err}\")\n",
    "            raise\n",
    "\n",
    "    def delete_records_with_source_U_in_date_range(self, start_date, end_date, batch_size=100000):\n",
    "        \"\"\"\n",
    "        Delete records where source is 'U' within a specified date range, in 15-day increments, with retry and batching\n",
    "        \n",
    "        :param start_date: Start date for the range in 'YYYY-MM-DD' format\n",
    "        :param end_date: End date for the range in 'YYYY-MM-DD' format\n",
    "        :param batch_size: Number of records to delete in each batch\n",
    "        \"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        total_deleted = 0\n",
    "\n",
    "        try:\n",
    "            conn = self._create_connection()\n",
    "            conn.autocommit = False  # Disable autocommit\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            # Convert start_date and end_date to datetime objects\n",
    "            current_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "            end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "            \n",
    "            # Print and log start of deletion process\n",
    "            print(\"ðŸš€ Starting deletion process...\")\n",
    "            logger.info(\"ðŸš€ Starting deletion process...\")\n",
    "\n",
    "            # Iterate over the date range in 15-day increments\n",
    "            while current_date <= end_date:\n",
    "                next_date = current_date + timedelta(days=5)\n",
    "                \n",
    "                # Initial check to estimate total records to delete in this 15-day range\n",
    "                count_query = f\"\"\"\n",
    "                SELECT COUNT(*) FROM taxi_fhv_data \n",
    "                WHERE source = 'U' \n",
    "                AND Pickup_datetime BETWEEN '{current_date.strftime('%Y-%m-%d')}' AND '{next_date.strftime('%Y-%m-%d')}'\n",
    "                \"\"\"\n",
    "                cursor.execute(count_query)\n",
    "                total_records = cursor.fetchone()[0]\n",
    "                logger.info(f\"ðŸ“Š Total records to delete from {current_date.strftime('%Y-%m-%d')} to {next_date.strftime('%Y-%m-%d')}: {total_records}\")\n",
    "                print(f\"ðŸ“Š Total records to delete from {current_date.strftime('%Y-%m-%d')} to {next_date.strftime('%Y-%m-%d')}: {total_records}\")\n",
    "\n",
    "                # Delete in batches to reduce lock contention\n",
    "                while True:\n",
    "                    delete_query = f\"\"\"\n",
    "                    DELETE FROM taxi_fhv_data \n",
    "                    WHERE source = 'U'\n",
    "                    AND Pickup_datetime BETWEEN '{current_date.strftime('%Y-%m-%d')}' AND '{next_date.strftime('%Y-%m-%d')}'\n",
    "                    LIMIT {batch_size}\n",
    "                    \"\"\"\n",
    "\n",
    "                    # Retry mechanism with exponential backoff\n",
    "                    max_retries = 5\n",
    "                    for attempt in range(max_retries):\n",
    "                        try:\n",
    "                            cursor.execute(delete_query)\n",
    "                            conn.commit()\n",
    "                            rows_deleted = cursor.rowcount\n",
    "                            total_deleted += rows_deleted\n",
    "\n",
    "                            logger.info(f\"ðŸ—‘ï¸ Batch delete - Rows deleted from {current_date.strftime('%Y-%m-%d')} to {next_date.strftime('%Y-%m-%d')}: {rows_deleted}\")\n",
    "                            print(f\"ðŸ—‘ï¸ Batch delete - Rows deleted from {current_date.strftime('%Y-%m-%d')} to {next_date.strftime('%Y-%m-%d')}: {rows_deleted}\")\n",
    "\n",
    "                            # Exit if no more records to delete\n",
    "                            if rows_deleted == 0:\n",
    "                                break\n",
    "\n",
    "                            break  # Successful deletion\n",
    "                        except mysql.connector.Error as err:\n",
    "                            if err.errno == 1205:  # Lock wait timeout\n",
    "                                wait_time = 2 ** attempt\n",
    "                                logger.warning(f\"â³ Lock timeout. Retry {attempt + 1}/{max_retries}. Waiting {wait_time} seconds\")\n",
    "                                print(f\"â³ Lock timeout. Retry {attempt + 1}/{max_retries}. Waiting {wait_time} seconds\")\n",
    "                                time.sleep(wait_time)\n",
    "                                conn.rollback()\n",
    "                            else:\n",
    "                                raise\n",
    "\n",
    "                    # Break main loop if no more records\n",
    "                    if rows_deleted == 0:\n",
    "                        break\n",
    "\n",
    "                current_date = next_date + timedelta(days=5)\n",
    "\n",
    "            logger.info(f\"ðŸ“ˆ Total records deleted: {total_deleted}\")\n",
    "            print(f\"ðŸ“ˆ Total records deleted: {total_deleted}\")\n",
    "            return total_deleted\n",
    "\n",
    "        except Exception as e:\n",
    "            if conn:\n",
    "                conn.rollback()\n",
    "            logger.error(f\"âŒ Deletion error: {e}\")\n",
    "            print(f\"âŒ Deletion error: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            # Ensure resources are closed\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "            \n",
    "            # Print and log end of deletion process\n",
    "            print(\"âœ… Deletion process completed.\")\n",
    "            logger.info(\"âœ… Deletion process completed.\")\n",
    "\n",
    "def main():\n",
    "    # Execution\n",
    "    db_manager = DatabaseManager()\n",
    "    start_date = '2024-08-26'\n",
    "    end_date = '2024-08-31'\n",
    "    \n",
    "    try:\n",
    "        deleted_count = db_manager.delete_records_with_source_U_in_date_range(start_date, end_date)\n",
    "        print(f\"âœ… Successfully deleted {deleted_count} records.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Deletion process failed: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear la nueva tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "\n",
    "# ðŸŒŸ Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# ðŸ” Database connection configuration\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv(\"DB_HOST\"),\n",
    "    'port': int(os.getenv(\"DB_PORT\", 3306)),\n",
    "    'user': os.getenv(\"DB_USER\"),\n",
    "    'password': os.getenv(\"DB_PASSWORD\"),\n",
    "    'database': os.getenv(\"DB_NAME\")\n",
    "}\n",
    "\n",
    "def populate_enriched_taxi_data_table(batch_size=100000):\n",
    "    try:\n",
    "        # ðŸš€ Create SQLAlchemy engine for bulk operations\n",
    "        engine = create_engine(\n",
    "            f\"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "        )\n",
    "        \n",
    "        # ðŸ”— Establish initial connection to execute query\n",
    "        connection = pymysql.connect(**DB_CONFIG, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        # ðŸ“Š Main extraction query\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            t.Pickup_datetime,\n",
    "            t.DropOff_datetime,\n",
    "            t.PULocationID,\n",
    "            t.DOLocationID,\n",
    "            z.Borough AS pickup_borough,\n",
    "            tr.Vol AS traffic_volume,\n",
    "            YEAR(t.Pickup_datetime) AS pickup_year,\n",
    "            MONTH(t.Pickup_datetime) AS pickup_month,\n",
    "            DAY(t.Pickup_datetime) AS pickup_day,\n",
    "            HOUR(t.Pickup_datetime) AS pickup_hour,\n",
    "            MINUTE(t.Pickup_datetime) AS pickup_minute,\n",
    "            t.source\n",
    "        FROM \n",
    "            taxi_fhv_data t\n",
    "        JOIN \n",
    "            taxi_zones z ON t.PULocationID = z.LocationID\n",
    "        LEFT JOIN \n",
    "            trafico tr ON YEAR(t.Pickup_datetime) = tr.Yr \n",
    "                       AND MONTH(t.Pickup_datetime) = tr.M \n",
    "                       AND DAY(t.Pickup_datetime) = tr.D \n",
    "                       AND HOUR(t.Pickup_datetime) = tr.HH \n",
    "                       AND MINUTE(t.Pickup_datetime) = tr.MM\n",
    "        \"\"\"\n",
    "        \n",
    "        # ðŸ”„ Process data in batches\n",
    "        offset = 0\n",
    "        while True:\n",
    "            # ðŸ§© Modify query to use LIMIT and OFFSET for batch processing\n",
    "            batched_query = f\"{query} LIMIT {batch_size} OFFSET {offset}\"\n",
    "            df = pd.read_sql(batched_query, connection)\n",
    "            \n",
    "            # ðŸ›‘ Break if no more records\n",
    "            if df.empty:\n",
    "                break\n",
    "            \n",
    "            # ðŸ§¹ Handle potential None/NaN values\n",
    "            df['traffic_volume'] = df['traffic_volume'].fillna(0)\n",
    "            \n",
    "            # ðŸ’¾ Bulk insert using SQLAlchemy\n",
    "            df.to_sql('enriched_taxi_data', \n",
    "                      engine, \n",
    "                      if_exists='append', \n",
    "                      index=False, \n",
    "                      chunksize=10000)\n",
    "            \n",
    "            # â© Update offset\n",
    "            offset += batch_size\n",
    "            print(f\"ðŸš¦ Processed batch: {offset} rows\")\n",
    "        \n",
    "        connection.close()\n",
    "        engine.dispose()\n",
    "        print(\"âœ… Data enrichment completed successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during data enrichment: {e}\")\n",
    "\n",
    "# ðŸ Execute the enrichment process\n",
    "populate_enriched_taxi_data_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—„ï¸ Database Manager - Sistema de GestiÃ³n de Datos de Taxis FHV\n",
    "\n",
    "ðŸš• Sistema de Consulta y Logging para Base de Datos de Taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# ðŸ“ ConfiguraciÃ³n del logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
    "    filename='database_query.log'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DatabaseManager:\n",
    "    \"\"\"ðŸ—„ï¸ Administrador de conexiones y consultas a la base de datos\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # ðŸ”‘ Cargar variables de entorno\n",
    "        load_dotenv()\n",
    "        \n",
    "        # ðŸ”’ Obtener credenciales de la base de datos\n",
    "        self.db_host = os.getenv('DB_HOST')\n",
    "        self.db_user = os.getenv('DB_USER')\n",
    "        self.db_password = os.getenv('DB_PASSWORD')\n",
    "        self.db_name = os.getenv('DB_NAME')\n",
    "\n",
    "    def _create_connection(self):\n",
    "        \"\"\"ðŸ”Œ Crear una conexiÃ³n a la base de datos\"\"\"\n",
    "        try:\n",
    "            conn = mysql.connector.connect(\n",
    "                host=self.db_host,\n",
    "                user=self.db_user,\n",
    "                password=self.db_password,\n",
    "                database=self.db_name\n",
    "            )\n",
    "            logger.info(\"ðŸŸ¢ ConexiÃ³n establecida exitosamente\")\n",
    "            return conn\n",
    "        except mysql.connector.Error as err:\n",
    "            logger.error(f\"ðŸ”´ Error de conexiÃ³n: {err}\")\n",
    "            raise\n",
    "\n",
    "    def count_records(self):\n",
    "        \"\"\"ðŸ“Š Ejecutar un COUNT(1) en la tabla taxi_fhv_data\"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        try:\n",
    "            conn = self._create_connection()\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # ðŸ” Ejecutar la consulta COUNT(1)\n",
    "            query = \"SELECT COUNT(1) FROM taxi_fhv_data WHERE source = 'U'\"\n",
    "            cursor.execute(query)\n",
    "            count = cursor.fetchone()[0]\n",
    "            logger.info(f\"ðŸ“ˆ Total de registros: {count}\")\n",
    "            print(f\"ðŸ“ˆ Total de registros: {count}\")\n",
    "            return count\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ Error en la consulta: {e}\")\n",
    "            print(f\"âŒ Error en la consulta: {e}\")\n",
    "            raise\n",
    "            \n",
    "        finally:\n",
    "            # ðŸ§¹ Limpieza de recursos\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                logger.info(\"ðŸ”Œ ConexiÃ³n cerrada\")\n",
    "            \n",
    "            # âœ… Registro de finalizaciÃ³n\n",
    "            print(\"âœ… Proceso de consulta completado\")\n",
    "            logger.info(\"âœ… Proceso de consulta completado\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"ðŸŽ¯ FunciÃ³n principal de ejecuciÃ³n\"\"\"\n",
    "    db_manager = DatabaseManager()\n",
    "    \n",
    "    try:\n",
    "        record_count = db_manager.count_records()\n",
    "        print(f\"ðŸŽ‰ Conteo exitoso: {record_count} registros\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ El proceso fallÃ³: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
    "    filename='database_indexing.log'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DatabaseManager:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        self.db_host = os.getenv('DB_HOST')\n",
    "        self.db_user = os.getenv('DB_USER')\n",
    "        self.db_password = os.getenv('DB_PASSWORD')\n",
    "        self.db_name = os.getenv('DB_NAME')\n",
    "\n",
    "    def _create_connection(self):\n",
    "        try:\n",
    "            conn = mysql.connector.connect(\n",
    "                host=self.db_host,\n",
    "                user=self.db_user,\n",
    "                password=self.db_password,\n",
    "                database=self.db_name\n",
    "            )\n",
    "            logger.info(\"ðŸŸ¢ ConexiÃ³n establecida exitosamente\")\n",
    "            return conn\n",
    "        except mysql.connector.Error as err:\n",
    "            logger.error(f\"ðŸ”´ Error de conexiÃ³n: {err}\")\n",
    "            raise\n",
    "\n",
    "    def create_indexes(self):\n",
    "        \"\"\"ðŸ” Crear Ã­ndices para optimizar consultas\"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        try:\n",
    "            conn = self._create_connection()\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            # Lista de Ã­ndices a crear con verificaciÃ³n previa\n",
    "            indexes = [\n",
    "                \"CREATE INDEX idx_pickup_dropoff ON taxi_fhv_data (pickup_datetime, dropoff_datetime)\",\n",
    "                \"CREATE INDEX idx_pickup ON taxi_fhv_data (pickup_datetime)\",\n",
    "                \"CREATE INDEX idx_dropoff ON taxi_fhv_data (dropoff_datetime)\"\n",
    "            ]\n",
    "\n",
    "            existing_indexes_query = \"\"\"\n",
    "            SELECT index_name\n",
    "            FROM information_schema.statistics\n",
    "            WHERE table_schema = %s\n",
    "            AND table_name = 'taxi_fhv_data'\n",
    "            \"\"\"\n",
    "            cursor.execute(existing_indexes_query, (self.db_name,))\n",
    "            existing_indexes = cursor.fetchall()\n",
    "            existing_indexes = [row[0] for row in existing_indexes]\n",
    "\n",
    "            # Crear Ã­ndices solo si no existen\n",
    "            for index_query in indexes:\n",
    "                index_name = index_query.split()[2]\n",
    "                if index_name not in existing_indexes:\n",
    "                    cursor.execute(index_query)\n",
    "                    logger.info(f\"âœ… Ãndice creado: {index_query}\")\n",
    "                    print(f\"âœ… Ãndice creado: {index_query}\")\n",
    "                else:\n",
    "                    logger.info(f\"ðŸŸ¡ Ãndice ya existe: {index_name}\")\n",
    "                    print(f\"ðŸŸ¡ Ãndice ya existe: {index_name}\")\n",
    "\n",
    "            # Confirmar cambios\n",
    "            conn.commit()\n",
    "            logger.info(\"ðŸŽ‰ Todos los Ã­ndices creados exitosamente\")\n",
    "            print(\"ðŸŽ‰ Todos los Ã­ndices creados exitosamente\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ Error al crear Ã­ndices: {e}\")\n",
    "            print(f\"âŒ Error al crear Ã­ndices: {e}\")\n",
    "            raise\n",
    "\n",
    "        finally:\n",
    "            # Limpiar recursos\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                logger.info(\"ðŸ”Œ ConexiÃ³n cerrada\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"ðŸŽ¯ FunciÃ³n principal de ejecuciÃ³n\"\"\"\n",
    "    db_manager = DatabaseManager()\n",
    "    \n",
    "    try:\n",
    "        db_manager.create_indexes()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ El proceso fallÃ³: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
