{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script de Importación de Trafico de NYC a MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 100000 filas en este bloque. Total filas insertadas: 100000\n",
      "Se han insertado un total de 109248 filas en la base de datos.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener las variables de entorno\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "csv_file_path = 'Automated_Traffic_Volume_Counts.csv'  # Asegúrate de actualizar esto con tu archivo CSV correcto\n",
    "\n",
    "# Verificar si las variables de entorno se cargaron correctamente\n",
    "if not all([db_host, db_user, db_password, db_name, db_port]):\n",
    "    raise ValueError(\"No se pudieron cargar todas las variables de entorno. Por favor verifica el archivo .env.\")\n",
    "\n",
    "# Cargar el archivo CSV en un DataFrame de pandas\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "except FileNotFoundError as e:\n",
    "    raise FileNotFoundError(f\"El archivo {csv_file_path} no se encuentra. Por favor verifica la ruta.\")\n",
    "\n",
    "# Filtrar los datos desde enero 2023 hasta agosto 2024\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2024, 8, 31)\n",
    "\n",
    "# Ensure the columns are in the correct format\n",
    "df['Yr'] = df['Yr'].astype(int)\n",
    "df['M'] = df['M'].astype(int)\n",
    "df['D'] = df['D'].astype(int)\n",
    "df['HH'] = df['HH'].astype(int)\n",
    "df['MM'] = df['MM'].astype(int)\n",
    "\n",
    "# Create a datetime column\n",
    "df['datetime'] = pd.to_datetime(df[['Yr', 'M', 'D', 'HH', 'MM']].rename(columns={'Yr': 'year', 'M': 'month', 'D': 'day', 'HH': 'hour', 'MM': 'minute'}))\n",
    "\n",
    "df_filtered = df[(df['datetime'] >= start_date) & (df['datetime'] <= end_date)].copy()\n",
    "\n",
    "# Seleccionar solo las columnas necesarias para el análisis\n",
    "columns_to_keep = ['RequestID', 'Boro', 'Yr', 'M', 'D', 'HH', 'MM', 'Vol', 'SegmentID', 'WktGeom', 'street', 'Direction']\n",
    "df_filtered = df_filtered[columns_to_keep]\n",
    "\n",
    "# Conectar a la base de datos MySQL\n",
    "try:\n",
    "    db_connection = mysql.connector.connect(\n",
    "        host=db_host,\n",
    "        user=db_user,\n",
    "        password=db_password,\n",
    "        database=db_name,\n",
    "        port=int(db_port)\n",
    "    )\n",
    "except mysql.connector.Error as err:\n",
    "    raise mysql.connector.Error(f\"Error al conectar a la base de datos: {err}\")\n",
    "\n",
    "cursor = db_connection.cursor()\n",
    "\n",
    "# Insertar los datos filtrados del DataFrame en bloques de 100,000 filas\n",
    "chunk_size = 100000\n",
    "rows_inserted = 0\n",
    "for start in range(0, len(df_filtered), chunk_size):\n",
    "    end = start + chunk_size\n",
    "    chunk = df_filtered.iloc[start:end]\n",
    "\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO trafico (RequestID, Boro, Yr, M, D, HH, MM, Vol, SegmentID, WktGeom, Direction)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    data = [(\n",
    "        row['RequestID'], row['Boro'], row['Yr'], row['M'], row['D'], row['HH'], row['MM'], row['Vol'],\n",
    "        row['SegmentID'], row['WktGeom'], row['Direction']\n",
    "    ) for _, row in chunk.iterrows()]\n",
    "\n",
    "    cursor.executemany(insert_query, data)\n",
    "    rows_inserted += len(data)\n",
    "    \n",
    "    # Imprimir el progreso solo cada 10 bloques\n",
    "    if start // chunk_size % 10 == 0:\n",
    "        print(f\"Se han insertado {len(data)} filas en este bloque. Total filas insertadas: {rows_inserted}\")\n",
    "\n",
    "# Confirmar los cambios y cerrar la conexión\n",
    "db_connection.commit()\n",
    "cursor.close()\n",
    "db_connection.close()\n",
    "\n",
    "# Mostrar el número total de filas insertadas\n",
    "print(f\"Se han insertado un total de {rows_inserted} filas en la base de datos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script de Importación de Temperaturas Promedio de NYC a MySQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 12 filas en la base de datos.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener las variables de entorno\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "csv_file_path = 'temperaturas_promedio_nyc_mensual.csv'  # Asegúrate de actualizar esto con tu archivo CSV correcto\n",
    "\n",
    "# Verificar si las variables de entorno se cargaron correctamente\n",
    "if not all([db_host, db_user, db_password, db_name, db_port]):\n",
    "    raise ValueError(\"No se pudieron cargar todas las variables de entorno. Por favor verifica el archivo .env.\")\n",
    "\n",
    "# Cargar el archivo CSV en un DataFrame de pandas\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "except FileNotFoundError as e:\n",
    "    raise FileNotFoundError(f\"El archivo {csv_file_path} no se encuentra. Por favor verifica la ruta.\")\n",
    "\n",
    "# Conectar a la base de datos MySQL\n",
    "try:\n",
    "    db_connection = mysql.connector.connect(\n",
    "        host=db_host,\n",
    "        user=db_user,\n",
    "        password=db_password,\n",
    "        database=db_name,\n",
    "        port=int(db_port)\n",
    "    )\n",
    "except mysql.connector.Error as err:\n",
    "    raise mysql.connector.Error(f\"Error al conectar a la base de datos: {err}\")\n",
    "\n",
    "cursor = db_connection.cursor()\n",
    "\n",
    "# Insertar los datos del DataFrame en la tabla MySQL\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO temperaturas (Mes, Manhattan, Brooklyn, Queens, The_Bronx, Staten_Island)\n",
    "VALUES (%s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "data = [tuple(row) for row in df.values]\n",
    "\n",
    "cursor.executemany(insert_query, data)\n",
    "\n",
    "# Confirmar los cambios y cerrar la conexión\n",
    "db_connection.commit()\n",
    "cursor.close()\n",
    "db_connection.close()\n",
    "\n",
    "# Mostrar el número de filas insertadas\n",
    "print(f\"Se han insertado {len(data)} filas en la base de datos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script de Importación de Taxi_Zones de NYC a MySQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Configuración de la conexión a la base de datos\n",
    "def procesar_archivo_taxi_zones(ruta_archivo):\n",
    "    try:\n",
    "        # Configuración de base de datos\n",
    "        db_host = os.getenv(\"DB_HOST\")\n",
    "        db_port = int(os.getenv(\"DB_PORT\", 3306))\n",
    "        db_user = os.getenv(\"DB_USER\")\n",
    "        db_password = os.getenv(\"DB_PASSWORD\")\n",
    "        db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "        # Leer el archivo CSV\n",
    "        df = pd.read_csv(ruta_archivo)\n",
    "        print(f\"✅ Archivo leído: {ruta_archivo}\")\n",
    "        print(f\"📊 Columnas: {df.columns.tolist()}\")\n",
    "\n",
    "        # Validar columnas\n",
    "        expected_columns = ['OBJECTID', 'Shape_Leng', 'the_geom', 'Shape_Area', 'zone', 'LocationID', 'borough']\n",
    "        if not all(column in df.columns for column in expected_columns):\n",
    "            print(f\"❌ Columnas faltantes: {expected_columns}\")\n",
    "            return False\n",
    "\n",
    "        # Eliminar duplicados\n",
    "        duplicados = df[df.duplicated(subset=['LocationID'], keep=False)]\n",
    "        if not duplicados.empty:\n",
    "            print(f\"🚨 Duplicados encontrados: {len(duplicados)}\")\n",
    "            df = df.drop_duplicates(subset=['LocationID'])\n",
    "\n",
    "        # Conectar a la base de datos\n",
    "        connection = pymysql.connect(\n",
    "            host=db_host,\n",
    "            port=db_port,\n",
    "            user=db_user,\n",
    "            password=db_password,\n",
    "            database=db_name,\n",
    "            charset='utf8mb4',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        print(\"🔌 Conexión a MySQL establecida\")\n",
    "\n",
    "        try:\n",
    "            cursor = connection.cursor()\n",
    "            \n",
    "            # Preparar consulta de inserción\n",
    "            insert_query = \"\"\"\n",
    "            INSERT IGNORE INTO taxi_zones (OBJECTID, Shape_Leng, the_geom, Shape_Area, zone, LocationID, borough)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            \n",
    "            # Preparar datos para inserción\n",
    "            data = [(\n",
    "                row['OBJECTID'],\n",
    "                row['Shape_Leng'],\n",
    "                row['the_geom'],\n",
    "                row['Shape_Area'],\n",
    "                row['zone'],\n",
    "                row['LocationID'],\n",
    "                row['borough']\n",
    "            ) for _, row in df.iterrows()]\n",
    "            \n",
    "            # Ejecutar inserción\n",
    "            cursor.executemany(insert_query, data)\n",
    "\n",
    "            # Confirmar cambios\n",
    "            connection.commit()\n",
    "            print(f\"✅ {len(df)} filas insertadas exitosamente\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error en inserción: {e}\")\n",
    "            return False\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error general: {e}\")\n",
    "        return False\n",
    "\n",
    "# Uso del script\n",
    "if __name__ == \"__main__\":\n",
    "    ruta_archivo = \"taxi_zones.csv\"  # Cambia esto por la ruta de tu archivo\n",
    "    resultado = procesar_archivo_taxi_zones(ruta_archivo)\n",
    "    \n",
    "    if resultado:\n",
    "        print(\"🎉 Proceso completado con éxito\")\n",
    "    else:\n",
    "        print(\"❌ Proceso fallido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultas en MYSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# 📝 Configuración del logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
    "    filename='database_query.log'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DatabaseManager:\n",
    "    \"\"\"🗄️ Administrador de conexiones y consultas a la base de datos\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # 🔑 Cargar variables de entorno\n",
    "        load_dotenv()\n",
    "        \n",
    "        # 🔒 Obtener credenciales de la base de datos\n",
    "        self.db_host = os.getenv('DB_HOST')\n",
    "        self.db_user = os.getenv('DB_USER')\n",
    "        self.db_password = os.getenv('DB_PASSWORD')\n",
    "        self.db_name = os.getenv('DB_NAME')\n",
    "\n",
    "    def _create_connection(self):\n",
    "        \"\"\"🔌 Crear una conexión a la base de datos\"\"\"\n",
    "        try:\n",
    "            conn = mysql.connector.connect(\n",
    "                host=self.db_host,\n",
    "                user=self.db_user,\n",
    "                password=self.db_password,\n",
    "                database=self.db_name\n",
    "            )\n",
    "            logger.info(\"🟢 Conexión establecida exitosamente\")\n",
    "            return conn\n",
    "        except mysql.connector.Error as err:\n",
    "            logger.error(f\"🔴 Error de conexión: {err}\")\n",
    "            raise\n",
    "\n",
    "    def count_records(self):\n",
    "        \"\"\"📊 Ejecutar un COUNT(1) en la tabla taxi_fhv_data\"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        try:\n",
    "            conn = self._create_connection()\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # 🔍 Ejecutar la consulta COUNT(1)\n",
    "            query = \"SELECT COUNT(1) FROM taxi_fhv_data WHERE source = 'U'\"\n",
    "            cursor.execute(query)\n",
    "            count = cursor.fetchone()[0]\n",
    "            logger.info(f\"📈 Total de registros: {count}\")\n",
    "            print(f\"📈 Total de registros: {count}\")\n",
    "            return count\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Error en la consulta: {e}\")\n",
    "            print(f\"❌ Error en la consulta: {e}\")\n",
    "            raise\n",
    "            \n",
    "        finally:\n",
    "            # 🧹 Limpieza de recursos\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                logger.info(\"🔌 Conexión cerrada\")\n",
    "            \n",
    "            # ✅ Registro de finalización\n",
    "            print(\"✅ Proceso de consulta completado\")\n",
    "            logger.info(\"✅ Proceso de consulta completado\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"🎯 Función principal de ejecución\"\"\"\n",
    "    db_manager = DatabaseManager()\n",
    "    \n",
    "    try:\n",
    "        record_count = db_manager.count_records()\n",
    "        print(f\"🎉 Conteo exitoso: {record_count} registros\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ El proceso falló: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELiminar U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting deletion process...\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
    "    filename='database_deletion.log'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DatabaseManager:\n",
    "    def __init__(self):\n",
    "        # Load environment variables\n",
    "        load_dotenv()\n",
    "\n",
    "        # Get database credentials from environment variables\n",
    "        self.db_host = os.getenv('DB_HOST')\n",
    "        self.db_user = os.getenv('DB_USER')\n",
    "        self.db_password = os.getenv('DB_PASSWORD')\n",
    "        self.db_name = os.getenv('DB_NAME')\n",
    "\n",
    "    def _create_connection(self):\n",
    "        \"\"\"Create a database connection\"\"\"\n",
    "        try:\n",
    "            conn = mysql.connector.connect(\n",
    "                host=self.db_host,\n",
    "                user=self.db_user,\n",
    "                password=self.db_password,\n",
    "                database=self.db_name\n",
    "            )\n",
    "            return conn\n",
    "        except mysql.connector.Error as err:\n",
    "            logger.error(f\"🔴 Connection error: {err}\")\n",
    "            raise\n",
    "\n",
    "    def delete_records_with_source_U_in_date_range(self, start_date, end_date, batch_size=100000):\n",
    "        \"\"\"\n",
    "        Delete records where source is 'U' within a specified date range, in 15-day increments, with retry and batching\n",
    "        \n",
    "        :param start_date: Start date for the range in 'YYYY-MM-DD' format\n",
    "        :param end_date: End date for the range in 'YYYY-MM-DD' format\n",
    "        :param batch_size: Number of records to delete in each batch\n",
    "        \"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        total_deleted = 0\n",
    "\n",
    "        try:\n",
    "            conn = self._create_connection()\n",
    "            conn.autocommit = False  # Disable autocommit\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            # Convert start_date and end_date to datetime objects\n",
    "            current_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "            end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "            \n",
    "            # Print and log start of deletion process\n",
    "            print(\"🚀 Starting deletion process...\")\n",
    "            logger.info(\"🚀 Starting deletion process...\")\n",
    "\n",
    "            # Iterate over the date range in 15-day increments\n",
    "            while current_date <= end_date:\n",
    "                next_date = current_date + timedelta(days=5)\n",
    "                \n",
    "                # Initial check to estimate total records to delete in this 15-day range\n",
    "                count_query = f\"\"\"\n",
    "                SELECT COUNT(*) FROM taxi_fhv_data \n",
    "                WHERE source = 'U' \n",
    "                AND Pickup_datetime BETWEEN '{current_date.strftime('%Y-%m-%d')}' AND '{next_date.strftime('%Y-%m-%d')}'\n",
    "                \"\"\"\n",
    "                cursor.execute(count_query)\n",
    "                total_records = cursor.fetchone()[0]\n",
    "                logger.info(f\"📊 Total records to delete from {current_date.strftime('%Y-%m-%d')} to {next_date.strftime('%Y-%m-%d')}: {total_records}\")\n",
    "                print(f\"📊 Total records to delete from {current_date.strftime('%Y-%m-%d')} to {next_date.strftime('%Y-%m-%d')}: {total_records}\")\n",
    "\n",
    "                # Delete in batches to reduce lock contention\n",
    "                while True:\n",
    "                    delete_query = f\"\"\"\n",
    "                    DELETE FROM taxi_fhv_data \n",
    "                    WHERE source = 'U'\n",
    "                    AND Pickup_datetime BETWEEN '{current_date.strftime('%Y-%m-%d')}' AND '{next_date.strftime('%Y-%m-%d')}'\n",
    "                    LIMIT {batch_size}\n",
    "                    \"\"\"\n",
    "\n",
    "                    # Retry mechanism with exponential backoff\n",
    "                    max_retries = 5\n",
    "                    for attempt in range(max_retries):\n",
    "                        try:\n",
    "                            cursor.execute(delete_query)\n",
    "                            conn.commit()\n",
    "                            rows_deleted = cursor.rowcount\n",
    "                            total_deleted += rows_deleted\n",
    "\n",
    "                            logger.info(f\"🗑️ Batch delete - Rows deleted from {current_date.strftime('%Y-%m-%d')} to {next_date.strftime('%Y-%m-%d')}: {rows_deleted}\")\n",
    "                            print(f\"🗑️ Batch delete - Rows deleted from {current_date.strftime('%Y-%m-%d')} to {next_date.strftime('%Y-%m-%d')}: {rows_deleted}\")\n",
    "\n",
    "                            # Exit if no more records to delete\n",
    "                            if rows_deleted == 0:\n",
    "                                break\n",
    "\n",
    "                            break  # Successful deletion\n",
    "                        except mysql.connector.Error as err:\n",
    "                            if err.errno == 1205:  # Lock wait timeout\n",
    "                                wait_time = 2 ** attempt\n",
    "                                logger.warning(f\"⏳ Lock timeout. Retry {attempt + 1}/{max_retries}. Waiting {wait_time} seconds\")\n",
    "                                print(f\"⏳ Lock timeout. Retry {attempt + 1}/{max_retries}. Waiting {wait_time} seconds\")\n",
    "                                time.sleep(wait_time)\n",
    "                                conn.rollback()\n",
    "                            else:\n",
    "                                raise\n",
    "\n",
    "                    # Break main loop if no more records\n",
    "                    if rows_deleted == 0:\n",
    "                        break\n",
    "\n",
    "                current_date = next_date + timedelta(days=5)\n",
    "\n",
    "            logger.info(f\"📈 Total records deleted: {total_deleted}\")\n",
    "            print(f\"📈 Total records deleted: {total_deleted}\")\n",
    "            return total_deleted\n",
    "\n",
    "        except Exception as e:\n",
    "            if conn:\n",
    "                conn.rollback()\n",
    "            logger.error(f\"❌ Deletion error: {e}\")\n",
    "            print(f\"❌ Deletion error: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            # Ensure resources are closed\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "            \n",
    "            # Print and log end of deletion process\n",
    "            print(\"✅ Deletion process completed.\")\n",
    "            logger.info(\"✅ Deletion process completed.\")\n",
    "\n",
    "def main():\n",
    "    # Execution\n",
    "    db_manager = DatabaseManager()\n",
    "    start_date = '2024-08-26'\n",
    "    end_date = '2024-08-31'\n",
    "    \n",
    "    try:\n",
    "        deleted_count = db_manager.delete_records_with_source_U_in_date_range(start_date, end_date)\n",
    "        print(f\"✅ Successfully deleted {deleted_count} records.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Deletion process failed: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
