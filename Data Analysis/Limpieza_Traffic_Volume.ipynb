{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerias y archivo de trafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del dataset:\n",
      "Index(['RequestID', 'Boro', 'Yr', 'M', 'D', 'HH', 'MM', 'Vol', 'SegmentID',\n",
      "       'WktGeom', 'street', 'fromSt', 'toSt', 'Direction'],\n",
      "      dtype='object')\n",
      "\n",
      "Primeras filas del dataset:\n",
      "   RequestID    Boro    Yr  M   D  HH  MM  Vol  SegmentID  \\\n",
      "0      32970  Queens  2021  4  30   2   0    0     149701   \n",
      "1      32970  Queens  2021  4  30   2  15    1     149701   \n",
      "2      32970  Queens  2021  4  30   2  30    0     149701   \n",
      "3      32970  Queens  2021  4  30   2  45    0     149701   \n",
      "4      32970  Queens  2021  4  30   3   0    1     149701   \n",
      "\n",
      "                                        WktGeom          street  \\\n",
      "0  POINT (997407.0998491726 208620.92612708386)  PULASKI BRIDGE   \n",
      "1  POINT (997407.0998491726 208620.92612708386)  PULASKI BRIDGE   \n",
      "2  POINT (997407.0998491726 208620.92612708386)  PULASKI BRIDGE   \n",
      "3  POINT (997407.0998491726 208620.92612708386)  PULASKI BRIDGE   \n",
      "4  POINT (997407.0998491726 208620.92612708386)  PULASKI BRIDGE   \n",
      "\n",
      "                    fromSt      toSt Direction  \n",
      "0  Newtown Creek Shoreline  Dead end        NB  \n",
      "1  Newtown Creek Shoreline  Dead end        NB  \n",
      "2  Newtown Creek Shoreline  Dead end        NB  \n",
      "3  Newtown Creek Shoreline  Dead end        NB  \n",
      "4  Newtown Creek Shoreline  Dead end        NB  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo CSV\n",
    "file_path = 'Automated_Traffic_Volume_Counts_20241108.csv'\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Mostrar las columnas del dataset\n",
    "print(\"Columnas del dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Mostrar las primeras filas del dataset para tener una idea de los datos\n",
    "print(\"\\nPrimeras filas del dataset:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se eliminan columnas irrelevantes para el analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Boro    Yr  M   D  HH  MM  Vol  SegmentID\n",
      "0  Queens  2021  4  30   2   0    0     149701\n",
      "1  Queens  2021  4  30   2  15    1     149701\n",
      "2  Queens  2021  4  30   2  30    0     149701\n",
      "3  Queens  2021  4  30   2  45    0     149701\n",
      "4  Queens  2021  4  30   3   0    1     149701\n"
     ]
    }
   ],
   "source": [
    "columnas_a_eliminar = [\n",
    "    'RequestID',  # ID de la solicitud, probablemente irrelevante para el análisis.\n",
    "    'WktGeom',    # Coordenadas geométricas en formato WKT, no necesarias para el análisis actual.\n",
    "    'street',     # Nombre de la calle, podría no ser necesario dependiendo del análisis.\n",
    "    'fromSt',     # Calle de origen, podría no ser necesaria.\n",
    "    'toSt',       # Calle de destino, podría no ser necesaria.\n",
    "    'Direction'   # Dirección del tráfico, podría no ser necesaria para algunos tipos de análisis.\n",
    "]\n",
    "\n",
    "# Eliminar las columnas del DataFrame\n",
    "df = df.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame limpio\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mostrar la cantidad de filas en el DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de filas en el DataFrame:\n",
      "1712605\n"
     ]
    }
   ],
   "source": [
    "# Mostrar la cantidad de filas en el DataFrame\n",
    "print(\"Cantidad de filas en el DataFrame:\")\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mostrar la cantidad de valores nulos en cada columna del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de valores nulos en cada columna:\n",
      "Boro         0\n",
      "Yr           0\n",
      "M            0\n",
      "D            0\n",
      "HH           0\n",
      "MM           0\n",
      "Vol          0\n",
      "SegmentID    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mostrar la cantidad de valores nulos en cada columna del DataFrame\n",
    "print(\"Cantidad de valores nulos en cada columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buscar duplicados en el DataFrame\n",
    "**SE CONSERVAN**\n",
    "Motivo: Los datos de tráfico recolectados en intervalos de tiempo muy cortos pueden mostrar pocas variaciones entre registros consecutivos, resultando en duplicaciones aparentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas duplicadas donde todos los datos son iguales:\n",
      "             Boro    Yr  M   D  HH  MM  Vol  SegmentID\n",
      "15837      Queens  2020  9   7  12  15   56      91184\n",
      "21967      Queens  2020  9   7  21  30   29      91184\n",
      "21978      Queens  2020  9   8   0  15   12      91184\n",
      "21993      Queens  2020  9   8   4   0    4      91184\n",
      "23662    Brooklyn  2015  5  17  10   0  170      20379\n",
      "...           ...   ... ..  ..  ..  ..  ...        ...\n",
      "1711018    Queens  2015  5   1   3  30   22      62117\n",
      "1712593    Queens  2014  6  28  13  15    5      90610\n",
      "1712594    Queens  2014  6  28  13  30    5      90610\n",
      "1712596    Queens  2014  6  28  14   0    1      90610\n",
      "1712600    Queens  2014  6  28  15   0    6      90610\n",
      "\n",
      "[7701 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Buscar filas duplicadas donde todos los datos sean iguales\n",
    "duplicados_completos = df[df.duplicated()]\n",
    "\n",
    "# Mostrar las filas duplicadas\n",
    "print(\"Filas duplicadas donde todos los datos son iguales:\")\n",
    "print(duplicados_completos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unir las columnas yr, M, D, HH, MM en una sola columna de tipo datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Boro  Vol  SegmentID            datetime\n",
      "0  Queens    0     149701 2021-04-30 02:00:00\n",
      "1  Queens    1     149701 2021-04-30 02:15:00\n",
      "2  Queens    0     149701 2021-04-30 02:30:00\n",
      "3  Queens    0     149701 2021-04-30 02:45:00\n",
      "4  Queens    1     149701 2021-04-30 03:00:00\n"
     ]
    }
   ],
   "source": [
    "# Asegúrate de que las columnas tengan los nombres correctos\n",
    "df.rename(columns={'yr': 'Yr', 'm': 'M', 'd': 'D', 'hh': 'HH', 'mm': 'MM'}, inplace=True)\n",
    "\n",
    "# Unir las columnas Yr, M, D, HH, MM en una sola columna de tipo datetime\n",
    "df['datetime'] = pd.to_datetime(df[['Yr', 'M', 'D', 'HH', 'MM']].rename(columns={'Yr': 'year', 'M': 'month', 'D': 'day', 'HH': 'hour', 'MM': 'minute'}))\n",
    "\n",
    "# Eliminar las columnas originales\n",
    "df.drop(columns=['Yr', 'M', 'D', 'HH', 'MM'], inplace=True)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame para verificar la nueva columna\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
