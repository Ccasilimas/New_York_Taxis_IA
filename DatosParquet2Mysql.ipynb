{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener las credenciales de la base de datos desde las variables de entorno\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "\n",
    "# Conectar a MySQL utilizando las credenciales del archivo .env\n",
    "try:\n",
    "    engine = sqlalchemy.create_engine(f'mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "    connection = engine.connect()\n",
    "    print(\"Conexión a la base de datos establecida con éxito.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al conectar a la base de datos: {e}\")\n",
    "    raise\n",
    "\n",
    "# Ruta de la carpeta con los archivos\n",
    "folder_path = 'D:\\\\GitHub\\\\Proyecto Final\\\\Proyecto_final_Henry\\\\Dataset'\n",
    "\n",
    "# Columnas a mantener para green_tripdata\n",
    "columns_to_keep_green = ['lpep_pickup_datetime', 'lpep_dropoff_datetime', 'PULocationID', 'DOLocationID', 'trip_distance', 'total_amount']\n",
    "# Columnas a mantener para yellow_tripdata\n",
    "columns_to_keep_yellow = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'PULocationID', 'DOLocationID', 'trip_distance', 'total_amount']\n",
    "# Columnas a mantener para fhv_tripdata\n",
    "columns_to_keep_fhv = ['pickup_datetime', 'dropOff_datetime', 'PUlocationID', 'DOlocationID', 'Affiliated_base_number']\n",
    "\n",
    "# Leer todos los archivos en la carpeta y estandarizar las columnas\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.parquet'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        try:\n",
    "            # Leer archivo .parquet\n",
    "            print(f\"Leyendo archivo {file_path}\")\n",
    "            df = pd.read_parquet(file_path)\n",
    "            \n",
    "            # Verificar si es green_tripdata, yellow_tripdata o fhv_tripdata\n",
    "            if 'green' in filename.lower():\n",
    "                columns_to_keep = columns_to_keep_green\n",
    "                source_value = 'green_tripdata'\n",
    "            elif 'yellow' in filename.lower():\n",
    "                columns_to_keep = columns_to_keep_yellow\n",
    "                source_value = 'yellow_tripdata'\n",
    "            elif 'fhv' in filename.lower():\n",
    "                columns_to_keep = columns_to_keep_fhv\n",
    "                source_value = 'fhv_tripdata'\n",
    "            else:\n",
    "                print(f\"El archivo {filename} no es ni 'green', 'yellow' ni 'fhv'. Saltando.\")\n",
    "                continue\n",
    "            \n",
    "            # Verificar si el archivo contiene todas las columnas necesarias\n",
    "            if all(column in df.columns for column in columns_to_keep):\n",
    "                print(f\"El archivo {filename} contiene todas las columnas necesarias. Procesando...\")\n",
    "                \n",
    "                # Seleccionar columnas necesarias\n",
    "                df = df[columns_to_keep]\n",
    "                \n",
    "                # Renombrar columnas según sea necesario\n",
    "                if 'yellow' in filename.lower():\n",
    "                    df.rename(columns={\n",
    "                        'tpep_pickup_datetime': 'Pickup_datetime',\n",
    "                        'tpep_dropoff_datetime': 'DropOff_datetime',\n",
    "                        'trip_distance': 'trip_miles',\n",
    "                        'total_amount': 'driver_pay'\n",
    "                    }, inplace=True)\n",
    "                elif 'green' in filename.lower():\n",
    "                    df.rename(columns={\n",
    "                        'lpep_pickup_datetime': 'Pickup_datetime',\n",
    "                        'lpep_dropoff_datetime': 'DropOff_datetime',\n",
    "                        'trip_distance': 'trip_miles',\n",
    "                        'total_amount': 'driver_pay'\n",
    "                    }, inplace=True)\n",
    "                elif 'fhv' in filename.lower():\n",
    "                    df.rename(columns={\n",
    "                        'pickup_datetime': 'Pickup_datetime',\n",
    "                        'dropOff_datetime': 'DropOff_datetime',\n",
    "                        'PUlocationID': 'PULocationID',\n",
    "                        'DOlocationID': 'DOLocationID'\n",
    "                    }, inplace=True)\n",
    "                    df['trip_miles'] = 0.0  # Agregar columna trip_miles con valores por defecto\n",
    "                    df['driver_pay'] = 0.0  # Agregar columna driver_pay con valores por defecto\n",
    "                \n",
    "                # Añadir la columna 'source'\n",
    "                df['source'] = source_value\n",
    "                \n",
    "                # Calcular trip_time como la diferencia entre DropOff_datetime y Pickup_datetime\n",
    "                df['Pickup_datetime'] = pd.to_datetime(df['Pickup_datetime'])\n",
    "                df['DropOff_datetime'] = pd.to_datetime(df['DropOff_datetime'])\n",
    "                df['trip_time'] = (df['DropOff_datetime'] - df['Pickup_datetime']).dt.total_seconds()\n",
    "                \n",
    "                # Dividir el DataFrame en bloques de 10,000 filas\n",
    "                num_chunks = len(df) // 10000 + 1\n",
    "                \n",
    "                for i in tqdm(range(num_chunks), desc=f\"Procesando {filename}\", unit=\"chunk\"):\n",
    "                    chunk = df[i * 10000:(i + 1) * 10000]\n",
    "                    chunk.to_sql(name='taxi_fhv_data', con=engine, if_exists='append', index=False)\n",
    "                    print(f\"Chunk {i+1}/{num_chunks} del archivo {filename} cargado exitosamente.\")\n",
    "                \n",
    "                print(f\"Datos del archivo {filename} cargados exitosamente.\")\n",
    "            else:\n",
    "                print(f\"El archivo {filename} no contiene todas las columnas necesarias. Saltando.\")\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Archivo {file_path} no encontrado. Saltando.\")\n",
    "        except KeyError as e:\n",
    "            print(f\"Error de columna en {file_path}: {e}. Saltando.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar el archivo {filename}: {e}\")\n",
    "\n",
    "# Ahora, inspecciona el archivo específico fhv_tripdata_2024-01.parquet\n",
    "file_to_inspect = 'fhv_tripdata_2024-01.parquet'\n",
    "file_path = os.path.join(folder_path, file_to_inspect)\n",
    "\n",
    "try:\n",
    "    # Leer archivo .parquet\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Mostrar las columnas del archivo\n",
    "    print(f\"Columnas del archivo {file_to_inspect}:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al leer {file_path}: {e}\")\n",
    "\n",
    "print(\"Proceso de estandarización y carga completo.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
